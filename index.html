<!DOCTYPE html>
<html lang="en">
  <head>
  <title>GenAI key takeaways assignment website</title>
    <meta name="description" content="Assignment detailing 3 things I learned about GenAI."/>
  </head>

  <body>
  <header>
   <h1>3 Key Takeaways for GenAI</h1>
  </header>
  
  <main>
<h1>Iteritive Process</h1>
<p>This week I learned about how writers when using Gen AI may have to adopt an iterative process when generating their subject matter, experimenting with phrasing, or refining their AI response. Responses to prompts, at first, may contain numerous inaccuracies or might not even 
  contain all the elements they wanted from their prompts, so users will have to develop over time both what they ask the AI, and, more practically, simply edit the AI themselves with their own knowledge of the subject matter or further research to correct the mistakes.
  Sometimes writers solely rely on refining AI with further prompts, which, while it can lead to eventually making something they want, this may cause one to repeatedly make additional prompts, further adding to their personal carbon footprint, just to eventually create something usable.
  When deciding if one should adjust their AI content, or if AI content ought not to be used, one needs to understand if their content is accurate, unbiased, complete in their information, relevant/useful to their given task, and consistent if prompted multiple times. AI generating different things after the same prompt is a key indicator that something may be wrong, 
  either with the prompt you are asking, or with the particular LLM's suitability to what you want to do. 
</p>

<h1>Boost productivity for tasks</h1>
<p>This week I learned about ways AI can be used to speed up the work tech writers do. Tech writers can make AI more efficient if they use action verbs like "create" or "summarize" when wanting AI to do specific things. Asking AI to clarify that certain elements of the response should
  be defined or classified by key adjectives is also helpful to generate more detailed responses. Tech writers may ask to summarize longer documents or pieces of writing, so that they can understand key topics about a given subject without having to read through more onerous texts. One may wonder, however, how much is 
lost when asking to summarize, and it may be difficult to check for accuracy when AI is detailing a text you did not read yourself. There is also a limit to how much one can possibly condense a piece of information when still being comprehensive, 
if, say, one attempts to summarize 5 pages of text into a single sentence, the AI may do its best to follow the task, but it may be near impossible to ascertain everything one needs. Beyond summaries, one can ask the AI to extract, or summarize, key pieces of data from a text, such as all mentions of X within a larger writing on a broader set of subjects.
One may need to check this for accuracy still, but it may be helpful to do this when wanting to retain or extract a key piece of information from a document, which does not make said piece of information the main focus. One can also ask to turn the information into a table or ordered list in some way, saving some time for tech writers who want to organize data. 
AI can also be used to translate text from one language to another. This is based on the languages of the texts used to train the AI, and can go into depth when doing this a different way than if one used google translate or a similar program when trying to understand information in a language one does not speak. Although, most GenAI models work best in English and a few 
other key languages, so those who speak a more obscure language might not be able to use Gen AI's functions. This can create inequality in a world where businesses rely on certain types of technology to operate at a level they deem necessary, and might leave behind those logistically unable to compete.
</p>
    
<h1>What you and others give to AI</h1>
<p>When one sends data into an AI algorithm via their prompt it can be risky to include personal information since certain AI tools store user data and use this information to train its algorithm. One should understand this if they wish to utilize their own writing within an AI prompt, and that it may be entirely possible for algorithms to produce content for others which takes from
your ideas without credit. This can be especially harmful if one uses another's work, or even personal information, without permission when trying to prompt AI, as this data can be taken in and redistributed to an unknown amount of users in the future. AI algorithms can also include biases that reflect the prejudices of data it is trained upon. For example asking for an AI image of a doctor
or a CEO may more likely show a man than a woman, due to the unbalanced amount of men depicted in these roles in general, that the AI then later detects as a trend to further reinforce this kind of bias. Since AI also mixes so much information together based upon its sources, asking it to generate a full citation may sometimes lead to the program generating an imitation of a formatted source, 
rather than a real piece of research. This could include falsely attributed titles and authors, fake titles all together or links which go nowhere. This is an example of AI "hallucinating," and explaining information which may make sense when read, but be entirely untrue or inaccurate in reality. These inconsistencies apply to AI images as well, most notabily in cases of somebody having the wrong
number of fingers or words being spelt incorrectly.</p>

<h2> Conclusion </h2>
<p> In conclusion this week I learned about the ways AI can make certain tasks more efficient, and how to be more efficient when creating something usable with AI. I also learned about some more of the downsides to AI and the unfair biases it may perpetuate based on training data. I also learned about the difficulty in maintaining privacy when trying to use an AI system to assess personal or private
  research data. AI may be useful to summarize information in a more specific way than previously possible, but it can be difficult to know just how trustworthy said summary is, when the AI itself is just following a pattern and doesn't really understand what it is saying.</p>

</main>
    
<footer>
<p>Zach Lebowitz 10/8/2025</p>
</footer>    
  

  
</body>
  
</html>
